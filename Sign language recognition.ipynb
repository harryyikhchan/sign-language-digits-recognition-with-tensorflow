{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign language digits recognition with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to manage the dataset\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import glob\n",
    "\n",
    "# Deep leearnig and machine learning libraries (Keras and scikit learn)\n",
    "from os import listdir\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Classic libraries with python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Data\"></a>\n",
    "## A look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "[[177. 179. 180. ... 171. 169. 167.]\n",
      " [177. 179. 180. ... 172. 171. 168.]\n",
      " [177. 180. 181. ... 171. 169. 168.]\n",
      " ...\n",
      " [145. 146. 148. ... 139. 138. 137.]\n",
      " [143. 144. 146. ... 136. 136. 134.]\n",
      " [140. 141. 144. ... 134. 133. 132.]]\n",
      "[[ 0.31620246  0.36621982  0.3912285  ...  0.16615036  0.116133\n",
      "   0.06611563]\n",
      " [ 0.31620246  0.36621982  0.3912285  ...  0.19115904  0.16615036\n",
      "   0.09112431]\n",
      " [ 0.31620246  0.3912285   0.41623718 ...  0.16615036  0.116133\n",
      "   0.09112431]\n",
      " ...\n",
      " [-0.48407537 -0.4590667  -0.4090493  ... -0.63412744 -0.6591361\n",
      "  -0.6841448 ]\n",
      " [-0.5340927  -0.50908405 -0.4590667  ... -0.7091535  -0.7091535\n",
      "  -0.75917083]\n",
      " [-0.60911876 -0.5841101  -0.50908405 ... -0.75917083 -0.7841795\n",
      "  -0.80918825]]\n",
      "0.0\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Settings:\n",
    "img_size = 64\n",
    "num_class = 11\n",
    "\n",
    "def get_img(data_path):\n",
    "    # Getting image array from path:\n",
    "    img = cv2.imread(data_path, 0)\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    return img\n",
    "\n",
    "def get_dataset(dataset_path='dataset'):\n",
    "    labels = listdir(dataset_path) # Geting labels\n",
    "    print(labels)\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i, label in enumerate(labels):\n",
    "        datas_path = dataset_path+'/'+label\n",
    "        for data in listdir(datas_path):\n",
    "            img = get_img(datas_path+'/'+data)\n",
    "            X.append(img)\n",
    "            Y.append(label)\n",
    "    # Create dateset:\n",
    "    X = np.array(X).astype('float32')\n",
    "    print(X[1])\n",
    "    # Normalized the input\n",
    "    X = (X - np.min(X))/(np.max(X) - np.min(X))\n",
    "    print(X[1])\n",
    "    Y = np.array(Y).astype('float32')\n",
    "    print(Y[1])\n",
    "    # Categorize the output into binary class matrix\n",
    "    Y = tf.keras.utils.to_categorical(Y, num_class)\n",
    "    print(Y[1])\n",
    "    return X, Y\n",
    "\n",
    "X,Y = get_dataset()\n",
    "# add another axis representing grey-scale\n",
    "X_axis = X[:,:,:,np.newaxis]\n",
    "print(Y)\n",
    "# Split the test set and validatio set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_axis, Y, test_size = 0.2 , random_state = 42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2 , random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images = 2219\n",
      "number of training examples = 1420\n",
      "number of test examples = 444\n",
      "number of test examples = 355\n",
      "X_train shape: (1420, 64, 64, 1)\n",
      "Y_train shape: (1420, 11)\n",
      "X_test shape: (444, 64, 64, 1)\n",
      "Y_test shape: (444, 11)\n"
     ]
    }
   ],
   "source": [
    "print (\"Total number of images = \" + str(X.shape[0]))\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_val.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='neuralNet'></a>\n",
    "\n",
    "## Model 1: Create our ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1420 samples, validate on 355 samples\n",
      "Epoch 1/30\n",
      "1420/1420 [==============================] - 2s 2ms/step - loss: 2.0954 - acc: 0.3901 - val_loss: 1.1058 - val_acc: 0.6338\n",
      "Epoch 2/30\n",
      "1420/1420 [==============================] - 2s 1ms/step - loss: 1.0343 - acc: 0.6528 - val_loss: 0.8481 - val_acc: 0.7380\n",
      "Epoch 3/30\n",
      "1420/1420 [==============================] - 2s 1ms/step - loss: 0.7594 - acc: 0.7387 - val_loss: 0.7282 - val_acc: 0.7521\n",
      "Epoch 4/30\n",
      "1420/1420 [==============================] - 2s 2ms/step - loss: 0.6104 - acc: 0.8007 - val_loss: 0.7725 - val_acc: 0.7324\n",
      "Epoch 5/30\n",
      "1420/1420 [==============================] - 2s 2ms/step - loss: 0.5065 - acc: 0.8218 - val_loss: 0.6385 - val_acc: 0.7944\n",
      "Epoch 6/30\n",
      "1420/1420 [==============================] - 2s 2ms/step - loss: 0.4598 - acc: 0.8472 - val_loss: 0.6819 - val_acc: 0.7746\n",
      "Epoch 7/30\n",
      "1420/1420 [==============================] - 2s 2ms/step - loss: 0.4324 - acc: 0.8570 - val_loss: 0.6374 - val_acc: 0.7944\n",
      "Epoch 8/30\n",
      "1420/1420 [==============================] - 2s 2ms/step - loss: 0.3636 - acc: 0.8761 - val_loss: 0.5487 - val_acc: 0.8113\n",
      "Epoch 9/30\n",
      "1420/1420 [==============================] - 2s 1ms/step - loss: 0.2946 - acc: 0.8965 - val_loss: 0.6194 - val_acc: 0.7915\n",
      "Epoch 10/30\n",
      "1420/1420 [==============================] - 2s 1ms/step - loss: 0.2260 - acc: 0.9141 - val_loss: 0.5434 - val_acc: 0.8310\n",
      "Epoch 11/30\n",
      "1420/1420 [==============================] - 2s 2ms/step - loss: 0.1930 - acc: 0.9366 - val_loss: 0.5066 - val_acc: 0.8592\n",
      "Epoch 12/30\n",
      "1420/1420 [==============================] - 2s 1ms/step - loss: 0.1879 - acc: 0.9303 - val_loss: 0.5476 - val_acc: 0.8141\n",
      "Epoch 13/30\n",
      "1420/1420 [==============================] - 2s 1ms/step - loss: 0.1830 - acc: 0.9387 - val_loss: 0.5962 - val_acc: 0.8366\n",
      "Epoch 14/30\n",
      "1420/1420 [==============================] - 2s 1ms/step - loss: 0.2032 - acc: 0.9303 - val_loss: 0.6145 - val_acc: 0.8085\n",
      "Epoch 15/30\n",
      "1420/1420 [==============================] - 2s 1ms/step - loss: 0.1414 - acc: 0.9535 - val_loss: 0.5128 - val_acc: 0.8592\n",
      "Epoch 16/30\n",
      "1420/1420 [==============================] - 2s 2ms/step - loss: 0.1307 - acc: 0.9521 - val_loss: 0.5865 - val_acc: 0.8338\n",
      "Epoch 17/30\n",
      "1420/1420 [==============================] - 2s 1ms/step - loss: 0.1457 - acc: 0.9507 - val_loss: 0.6553 - val_acc: 0.8254\n",
      "Epoch 18/30\n",
      "1420/1420 [==============================] - 2s 1ms/step - loss: 0.1710 - acc: 0.9472 - val_loss: 0.6802 - val_acc: 0.8310\n",
      "Epoch 19/30\n",
      "1420/1420 [==============================] - 2s 1ms/step - loss: 0.2003 - acc: 0.9380 - val_loss: 0.7329 - val_acc: 0.8056\n",
      "Epoch 20/30\n",
      "1420/1420 [==============================] - 2s 1ms/step - loss: 0.2173 - acc: 0.9303 - val_loss: 0.6050 - val_acc: 0.8197\n",
      "Epoch 21/30\n",
      "1420/1420 [==============================] - 2s 1ms/step - loss: 0.1686 - acc: 0.9528 - val_loss: 0.6133 - val_acc: 0.8338\n",
      "Epoch 22/30\n",
      "1420/1420 [==============================] - 2s 1ms/step - loss: 0.0833 - acc: 0.9669 - val_loss: 0.5460 - val_acc: 0.8648\n",
      "Epoch 23/30\n",
      "1420/1420 [==============================] - 2s 1ms/step - loss: 0.0783 - acc: 0.9676 - val_loss: 0.6864 - val_acc: 0.8338\n",
      "Epoch 24/30\n",
      "1420/1420 [==============================] - 2s 1ms/step - loss: 0.1061 - acc: 0.9669 - val_loss: 0.6950 - val_acc: 0.8479\n",
      "Epoch 25/30\n",
      "1420/1420 [==============================] - 2s 1ms/step - loss: 0.1225 - acc: 0.9563 - val_loss: 0.6942 - val_acc: 0.8225\n",
      "Epoch 26/30\n",
      "1420/1420 [==============================] - 3s 2ms/step - loss: 0.1103 - acc: 0.9690 - val_loss: 0.6922 - val_acc: 0.8338\n",
      "Epoch 27/30\n",
      "1420/1420 [==============================] - 3s 2ms/step - loss: 0.1375 - acc: 0.9549 - val_loss: 0.7518 - val_acc: 0.8197\n",
      "Epoch 28/30\n",
      "1420/1420 [==============================] - 2s 2ms/step - loss: 0.1154 - acc: 0.9592 - val_loss: 0.7160 - val_acc: 0.8254\n",
      "Epoch 29/30\n",
      "1420/1420 [==============================] - 3s 2ms/step - loss: 0.0885 - acc: 0.9697 - val_loss: 0.8131 - val_acc: 0.8141\n",
      "Epoch 30/30\n",
      "1420/1420 [==============================] - 3s 2ms/step - loss: 0.0778 - acc: 0.9690 - val_loss: 0.7957 - val_acc: 0.8169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x133aefbe0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(num_class, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model1.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"logs/model1\")\n",
    "model1.fit(X_train, Y_train, batch_size=32, validation_data=[X_val, Y_val], epochs=30, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='runTheModel'></a>\n",
    "\n",
    "## Evaluate the result of Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 11)                2827      \n",
      "=================================================================\n",
      "Total params: 2,231,819\n",
      "Trainable params: 2,231,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "444/444 [==============================] - 0s 190us/step\n",
      "Loss: 0.8646  Accuaracy: 0.8514%\n"
     ]
    }
   ],
   "source": [
    "model1.summary()\n",
    "score = model1.evaluate(X_test, Y_test)\n",
    "print('Loss: {:.4f}  Accuaracy: {:.4}%'.format(score[0],score[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='CNNModel'></a>\n",
    "\n",
    "## Model 2: Create our CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1420 samples, validate on 355 samples\n",
      "Epoch 1/30\n",
      "1420/1420 [==============================] - 6s 4ms/step - loss: 1.2737 - acc: 0.5979 - val_loss: 0.9618 - val_acc: 0.7183\n",
      "Epoch 2/30\n",
      "1420/1420 [==============================] - 5s 3ms/step - loss: 0.5041 - acc: 0.8366 - val_loss: 0.7027 - val_acc: 0.8225\n",
      "Epoch 3/30\n",
      "1420/1420 [==============================] - 4s 3ms/step - loss: 0.3021 - acc: 0.9077 - val_loss: 0.5038 - val_acc: 0.8732\n",
      "Epoch 4/30\n",
      "1420/1420 [==============================] - 5s 3ms/step - loss: 0.2204 - acc: 0.9317 - val_loss: 0.3739 - val_acc: 0.9155\n",
      "Epoch 5/30\n",
      "1420/1420 [==============================] - 4s 3ms/step - loss: 0.1567 - acc: 0.9535 - val_loss: 0.3629 - val_acc: 0.8704\n",
      "Epoch 6/30\n",
      "1420/1420 [==============================] - 5s 3ms/step - loss: 0.1092 - acc: 0.9725 - val_loss: 0.2648 - val_acc: 0.9352\n",
      "Epoch 7/30\n",
      "1420/1420 [==============================] - 5s 3ms/step - loss: 0.0800 - acc: 0.9803 - val_loss: 0.1989 - val_acc: 0.9268\n",
      "Epoch 8/30\n",
      "1420/1420 [==============================] - 5s 3ms/step - loss: 0.0514 - acc: 0.9923 - val_loss: 0.1660 - val_acc: 0.9549\n",
      "Epoch 9/30\n",
      "1420/1420 [==============================] - 5s 4ms/step - loss: 0.0581 - acc: 0.9873 - val_loss: 0.1472 - val_acc: 0.9690\n",
      "Epoch 10/30\n",
      "1420/1420 [==============================] - 5s 3ms/step - loss: 0.0475 - acc: 0.9887 - val_loss: 0.1931 - val_acc: 0.9380\n",
      "Epoch 11/30\n",
      "1420/1420 [==============================] - 5s 3ms/step - loss: 0.0525 - acc: 0.9852 - val_loss: 0.1592 - val_acc: 0.9408\n",
      "Epoch 12/30\n",
      "1420/1420 [==============================] - 5s 4ms/step - loss: 0.0472 - acc: 0.9894 - val_loss: 0.1277 - val_acc: 0.9606\n",
      "Epoch 13/30\n",
      "1420/1420 [==============================] - 6s 4ms/step - loss: 0.0359 - acc: 0.9923 - val_loss: 0.1362 - val_acc: 0.9662\n",
      "Epoch 14/30\n",
      "1420/1420 [==============================] - 5s 3ms/step - loss: 0.0314 - acc: 0.9951 - val_loss: 0.1475 - val_acc: 0.9549\n",
      "Epoch 15/30\n",
      "1420/1420 [==============================] - 6s 4ms/step - loss: 0.0362 - acc: 0.9923 - val_loss: 0.1364 - val_acc: 0.9634\n",
      "Epoch 16/30\n",
      "1420/1420 [==============================] - 5s 4ms/step - loss: 0.0377 - acc: 0.9923 - val_loss: 0.1512 - val_acc: 0.9493\n",
      "Epoch 17/30\n",
      "1420/1420 [==============================] - 5s 4ms/step - loss: 0.0287 - acc: 0.9915 - val_loss: 0.1388 - val_acc: 0.9408\n",
      "Epoch 18/30\n",
      "1420/1420 [==============================] - 6s 4ms/step - loss: 0.0291 - acc: 0.9937 - val_loss: 0.1111 - val_acc: 0.9746\n",
      "Epoch 19/30\n",
      "1420/1420 [==============================] - 6s 4ms/step - loss: 0.0244 - acc: 0.9951 - val_loss: 0.0960 - val_acc: 0.9606\n",
      "Epoch 20/30\n",
      "1420/1420 [==============================] - 6s 4ms/step - loss: 0.0174 - acc: 0.9979 - val_loss: 0.1075 - val_acc: 0.9662\n",
      "Epoch 21/30\n",
      "1420/1420 [==============================] - 6s 4ms/step - loss: 0.0129 - acc: 0.9979 - val_loss: 0.1160 - val_acc: 0.9662\n",
      "Epoch 22/30\n",
      "1420/1420 [==============================] - 7s 5ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0906 - val_acc: 0.9718\n",
      "Epoch 23/30\n",
      "1420/1420 [==============================] - 7s 5ms/step - loss: 0.0124 - acc: 0.9965 - val_loss: 0.1159 - val_acc: 0.9606\n",
      "Epoch 24/30\n",
      "1420/1420 [==============================] - 6s 4ms/step - loss: 0.0135 - acc: 0.9972 - val_loss: 0.1645 - val_acc: 0.9493\n",
      "Epoch 25/30\n",
      "1420/1420 [==============================] - 6s 4ms/step - loss: 0.0090 - acc: 0.9986 - val_loss: 0.1636 - val_acc: 0.9493\n",
      "Epoch 26/30\n",
      "1420/1420 [==============================] - 5s 4ms/step - loss: 0.0137 - acc: 0.9972 - val_loss: 0.1441 - val_acc: 0.9493\n",
      "Epoch 27/30\n",
      "1420/1420 [==============================] - 6s 5ms/step - loss: 0.0069 - acc: 0.9986 - val_loss: 0.1063 - val_acc: 0.9662\n",
      "Epoch 28/30\n",
      "1420/1420 [==============================] - 5s 3ms/step - loss: 0.0104 - acc: 0.9979 - val_loss: 0.0929 - val_acc: 0.9718\n",
      "Epoch 29/30\n",
      "1420/1420 [==============================] - 7s 5ms/step - loss: 0.0118 - acc: 0.9972 - val_loss: 0.1107 - val_acc: 0.9690\n",
      "Epoch 30/30\n",
      "1420/1420 [==============================] - 6s 4ms/step - loss: 0.0098 - acc: 0.9972 - val_loss: 0.1488 - val_acc: 0.9606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x136b6eac8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build our CNN\n",
    "model2 = tf.keras.models.Sequential()\n",
    "# Convolutional Blocks: (1) Convolution, (2) Activation, (3) Pooling\n",
    "model2.add(tf.keras.layers.Conv2D(input_shape=(64, 64, 1), filters=64, kernel_size=(4,4), strides=(2)))\n",
    "model2.add(tf.keras.layers.Activation('relu'))\n",
    "model2.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "#outputs a (20, 20, 32) matrix\n",
    "model2.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(4,4), strides=(1)))\n",
    "model2.add(tf.keras.layers.Activation('relu'))\n",
    "#outputs a (8, 8, 32) matrix\n",
    "model2.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "# dropout helps with over fitting by randomly dropping nodes each epoch\n",
    "model2.add(tf.keras.layers.Dropout(0.3))\n",
    "model2.add(tf.keras.layers.Flatten())\n",
    "model2.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model2.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model2.add(tf.keras.layers.Dense(num_class, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"logs/model2\")\n",
    "model2.fit(X_train, Y_train, batch_size=32, validation_data=[X_val, Y_val], epochs=30, callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='runTheModel'></a>\n",
    "\n",
    "## Evaluate the result of Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 31, 31, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 64)        65600     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 11)                2827      \n",
      "=================================================================\n",
      "Total params: 660,619\n",
      "Trainable params: 660,107\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Loss: 0.1974  Accuaracy: 0.9482%\n"
     ]
    }
   ],
   "source": [
    "model2.summary()\n",
    "score = model2.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Loss: {:.4f}  Accuaracy: {:.4}%'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Result is  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] , Answer is  [10]\n",
      "Predicted Result from Neural net: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] , Predicted Answer is  [10]\n",
      "Predicted Result from CNN: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] , Predicted Answer is  [10]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13893d438>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testNum = 500\n",
    "test_image = X_axis[testNum]\n",
    "plt.imshow(test_image[:,:,0])\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "result1 = model1.predict(test_image)\n",
    "result2 = model2.predict(test_image)\n",
    "# For external image\n",
    "# test_image = get_img('./test.jpg')\n",
    "# plt.imshow(test_img)\n",
    "# test_image = np.expand_dims(test_image, axis = 0)\n",
    "# test_image = test_image[:,:,:,np.newaxis]\n",
    "# test_image = np.array(test_image).astype('float32')\n",
    "# # Normalized the input\n",
    "# test_image = (test_image - np.min(test_image))/ (np.max(test_image) - np.min(test_image) )\n",
    "\n",
    "result1 = model1.predict(test_image)\n",
    "result2 = model2.predict(test_image)\n",
    "result1_val = [i for i, j in enumerate(np.round(result1,1)[0]) if j == max(np.round(result1,1)[0])]\n",
    "result2_val = [i for i, j in enumerate(np.round(result2,1)[0]) if j == max(np.round(result2,1)[0])]\n",
    "print('Correct Result is ',Y[testNum], ', Answer is ',[i for i, j in enumerate(Y[testNum]) if j == max(Y[testNum])])\n",
    "print('Predicted Result from Neural net:',   np.round(result1,1)[0], ', Predicted Answer is ',result1_val)\n",
    "print('Predicted Result from CNN:', np.round(result2,1)[0], ', Predicted Answer is ',result2_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: CNN Model with Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "42/42 [==============================] - 8s 187ms/step - loss: 2.1609 - acc: 0.3100 - val_loss: 2.5242 - val_acc: 0.2182\n",
      "Epoch 2/5\n",
      "42/42 [==============================] - 5s 131ms/step - loss: 1.5108 - acc: 0.4834 - val_loss: 1.0351 - val_acc: 0.6424\n",
      "Epoch 3/5\n",
      "42/42 [==============================] - 6s 131ms/step - loss: 1.0750 - acc: 0.6100 - val_loss: 0.8356 - val_acc: 0.7818\n",
      "Epoch 4/5\n",
      "42/42 [==============================] - 5s 109ms/step - loss: 0.8608 - acc: 0.7045 - val_loss: 0.7343 - val_acc: 0.8394\n",
      "Epoch 5/5\n",
      "42/42 [==============================] - 5s 121ms/step - loss: 0.7517 - acc: 0.7410 - val_loss: 0.9734 - val_acc: 0.6455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x135326c88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a more diverse dataset by rotating, shifting and zooming the image\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=16,\n",
    "    width_shift_range=0.12,\n",
    "    height_shift_range=0.12,\n",
    "    zoom_range=0.12\n",
    "    )\n",
    "   \n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n",
    "# Model3: Add Image Generate\n",
    "# build our CNN\n",
    "model3 = tf.keras.models.Sequential()\n",
    "\n",
    "# Convolutional Blocks: (1) Convolution, (2) Activation, (3) Pooling\n",
    "model3.add(tf.keras.layers.Conv2D(input_shape=(64, 64, 1), filters=64, kernel_size=(4,4), strides=(2)))\n",
    "model3.add(tf.keras.layers.Activation('relu'))\n",
    "model3.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "#outputs a (20, 20, 32) matrix\n",
    "model3.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(4,4), strides=(1)))\n",
    "model3.add(tf.keras.layers.Activation('relu'))\n",
    "#outputs a (8, 8, 32) matrix\n",
    "model3.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "# dropout helps with over fitting by randomly dropping nodes each epoch\n",
    "model3.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model3.add(tf.keras.layers.Flatten())\n",
    "model3.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model3.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model3.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"logs/model2\")\n",
    "model3.fit_generator(datagen.flow(X_train, Y_train, batch_size=32), validation_data=(X_val, Y_val), epochs=5, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the result of Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 31, 31, 64)        1088      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 64)        65600     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 660,362\n",
      "Trainable params: 659,850\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "Loss: 1.0555  Accuaracy: 0.6102%\n"
     ]
    }
   ],
   "source": [
    "model3.summary()\n",
    "tf.keras.models.save_model(\n",
    "    model3,\n",
    "    \"./CNN_model.h5\",\n",
    "    overwrite=True,\n",
    "    include_optimizer=True\n",
    ")\n",
    "score = model3.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Loss: {:.4f}  Accuaracy: {:.4}%'.format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay ! We clearly see an improvement ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
